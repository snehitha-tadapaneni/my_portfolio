<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Projects | Snehitha</title>
  <link rel="stylesheet" href="style.css"/>
</head>
<body>
  <!-- Header -->
  <header class="site-header">
    <nav class="nav container">
      <div class="brand">
        <div class="name">Snehitha Tadapaneni</div>
      </div>
      <div class="menu">
        <a href="index.html">Home</a>
        <a href="education.html">Education</a>
        <a href="projects.html" class="active">Projects</a>
        <a href="experience.html">Experience</a>
        <a href="skills.html">Skills</a>
        <a href="certifications.html">Certifications</a>
      </div>
    </nav>
  </header>

  <section class="section">
    <div class="container">
      <h2>Projects</h2>

     

        <div class="projects-list">

  <!-- Personal Project -->
  <div class="project-block">
    <h3>
      <a href="https://github.com/snehitha-tadapaneni/Multi-Agent-RAG-Research-Assistant" target="_blank" rel="noreferrer">
        Multi-Agent RAG Research Assistant
      </a>
    </h3>
    <p><strong>Tech:</strong> Python, IBM Watsonx, LangChain, ChromaDB, Gradio | <strong>Duration:</strong> Jun – Aug 2025</p>
    <ul>
      <li>Addressed the problem of researchers relying on unverified or incomplete information when reviewing large volumes of academic PDFs.</li>
      <li>Worked with unclear requirements due to highly unstructured inputs (scanned PDFs, tables, mixed formats) and vague expectations of “answer quality.”</li>
      <li>Decided to decompose a traditional RAG pipeline into specialized agents to improve traceability, accuracy, and trust in outputs.</li>
      <li>Focused KPIs on answer groundedness, retrieval relevance, and verification success rate rather than generative creativity.</li>
      <li>Enabled users to confidently decide whether information was suitable for citations, reports, or literature reviews.</li>
      <li>Explained results to non-technical users through a single-page interface showing sources, verification status, and spoken summaries.</li>
    </ul>
  </div>

  <!-- Masters Projects -->
  <div class="project-block">
    <h3>Analysis of Google Play Store Apps</h3>
    <p><strong>Tech:</strong> Python (Pandas, NumPy), Visualization | <strong>Duration:</strong> Oct – Dec 2024</p>
    <ul>
      <li>Analyzed what drives app success by studying installs, ratings, reviews, and pricing across thousands of Google Play Store apps.</li>
      <li>Handled ambiguous definitions of “success” by aligning metrics with realistic product and business decisions.</li>
      <li>Made key decisions around data cleaning (price formats, app sizes, genre inconsistencies) to avoid misleading insights.</li>
      <li>Prioritized KPIs such as rating distribution, review volume, update frequency, and install buckets over raw download counts.</li>
      <li>Provided insights that help teams decide where to invest effort (category focus, pricing strategy, update cadence).</li>
      <li>Presented findings using simple comparisons and visuals that non-technical stakeholders could immediately interpret.</li>
    </ul>
  </div>

  <div class="project-block">
    <h3>
      <a href="https://github.com/snehitha-tadapaneni/Data-mining-Project" target="_blank" rel="noreferrer">
        Neighborhood Crime Rates vs Residential Property Risk (Washington DC)
      </a>
    </h3>
    <p><strong>Tech:</strong> Python, Geospatial Analysis, Random Forest, LightGBM | <strong>Duration:</strong> Oct – Dec 2024</p>
    <ul>
      <li>Studied how neighborhood-level crime patterns affect residential property risk using 46,000+ crime records.</li>
      <li>Worked under unclear goals (prediction vs explanation), so delivered both interpretable insights and risk classification.</li>
      <li>Chose geospatial alignment with census tracts to ensure meaningful neighborhood comparisons.</li>
      <li>Used KPIs like hotspot stability, feature importance, and class-level model performance instead of raw accuracy.</li>
      <li>Helped stakeholders identify high-risk areas and understand socio-economic drivers such as unemployment and housing vacancy.</li>
      <li>Explained results through maps and plain-language summaries rather than technical model details.</li>
    </ul>
  </div>

  <div class="project-block">
    <h3>
      <a href="https://drive.google.com/drive/folders/1rLxFjEWa-tIEoa6y9iB6vXMJ9DtsPCWl" target="_blank" rel="noreferrer">
        Environmental Insights from NYC Street Tree Census & Air Quality Data
      </a>
    </h3>
    <p><strong>Tech:</strong> Tableau, Geospatial Analysis | <strong>Duration:</strong> Mar – May 2025</p>
    <ul>
      <li>Analyzed how tree density and biodiversity relate to air quality across New York City neighborhoods.</li>
      <li>Managed ambiguity caused by merging datasets from different sources, resolutions, and geographic boundaries.</li>
      <li>Decided to aggregate insights at the community-district level to support real urban planning decisions.</li>
      <li>Focused KPIs on PM2.5 levels, species diversity, tree health, and stewardship participation.</li>
      <li>Generated insights showing how biodiversity correlates with reduced pollution, informing sustainability planning.</li>
      <li>Communicated findings through an interactive Tableau dashboard designed for non-technical policy audiences.</li>
    </ul>
  </div>

  <div class="project-block">
    <h3>Customer Purchase Prediction</h3>
    <p><strong>Tech:</strong> Python, Classification Models | <strong>Duration:</strong> Mar – May 2025</p>
    <ul>
      <li>Built models to predict customer purchase likelihood to improve targeting and reduce wasted marketing spend.</li>
      <li>Worked with vague success criteria, so framed results around actionable customer ranking and threshold selection.</li>
      <li>Made design choices to handle class imbalance and prioritize interpretability alongside performance.</li>
      <li>Used KPIs such as precision-recall, ROC-AUC, and top-K lift rather than overall accuracy.</li>
      <li>Helped stakeholders decide whom to target based on risk-reward tradeoffs.</li>
      <li>Explained model outputs using business-oriented examples instead of algorithmic terminology.</li>
    </ul>
  </div>

  <div class="project-block">
    <h3>Hourly Power Consumption Forecasting (Morocco)</h3>
    <p><strong>Tech:</strong> Python, Time Series Analysis | <strong>Duration:</strong> Mar – May 2025</p>
    <ul>
      <li>Forecasted hourly power demand to support operational planning and energy management.</li>
      <li>Handled unclear forecasting horizons by evaluating multiple time windows and stability tradeoffs.</li>
      <li>Chose time-aware validation strategies to avoid data leakage.</li>
      <li>Tracked KPIs such as MAE and peak-hour error rather than average error alone.</li>
      <li>Supported decisions around peak-load risk and operational preparedness.</li>
      <li>Explained seasonality and demand drivers through simple trend visuals.</li>
    </ul>
  </div>

  <div class="project-block">
    <h3>Comparative Analysis: Threads vs Twitter Reviews</h3>
    <p><strong>Tech:</strong> NLP, Sentiment Analysis, Topic Modeling | <strong>Duration:</strong> Oct – Dec 2025</p>
    <ul>
      <li>Analyzed user reviews to compare sentiment and recurring themes across Threads and Twitter.</li>
      <li>Worked with noisy, unstructured text and unclear questions like “which platform is better.”</li>
      <li>Decided to combine lexicon-based and model-based sentiment methods for robustness.</li>
      <li>Focused KPIs on theme frequency, sentiment split, and trend consistency.</li>
      <li>Helped product teams identify feature pain points and competitive advantages.</li>
      <li>Summarized results as actionable themes with example quotes for non-technical stakeholders.</li>
    </ul>
  </div>

  <!-- Bachelors Projects -->
  <div class="project-block">
    <h3>Deep Learning Model for Eye Diseases Prediction</h3>
    <p><strong>Tech:</strong> Python, Deep Learning, Flask | <strong>Duration:</strong> May – Jul 2023</p>
    <ul>
      <li>Built an end-to-end system to predict eye diseases from medical images.</li>
      <li>Handled unclear real-world constraints such as image quality variation.</li>
      <li>Chose to deploy the model via a Flask API to ensure usability beyond notebooks.</li>
      <li>Tracked KPIs like accuracy, recall, and inference responsiveness.</li>
      <li>Demonstrated feasibility for preliminary screening workflows.</li>
      <li>Explained outputs in simple terms suitable for non-technical users.</li>
    </ul>
  </div>

  <div class="project-block">
    <h3>Web App for Text Extraction & Summarization (GPT-3)</h3>
    <p><strong>Tech:</strong> Python, LLM APIs | <strong>Duration:</strong> Jul – Dec 2023</p>
    <ul>
      <li>Automated extraction and summarization of long documents to reduce reading time.</li>
      <li>Handled ambiguous expectations of summary length and detail.</li>
      <li>Designed a simple workflow prioritizing usability over technical complexity.</li>
      <li>Focused KPIs on readability and time saved.</li>
      <li>Helped users decide what content required deeper reading.</li>
      <li>Presented results without exposing underlying model complexity.</li>
    </ul>
  </div>

  <div class="project-block">
    <h3>Data Hiding using Steganography & Visual Cryptography</h3>
    <p><strong>Tech:</strong> Python | <strong>Duration:</strong> Jul – Dec 2023</p>
    <ul>
      <li>Developed a secure data-hiding system for sensitive information sharing.</li>
      <li>Worked with open-ended requirements balancing security and usability.</li>
      <li>Chose layered protection instead of relying on a single security technique.</li>
      <li>Focused KPIs on extraction accuracy and robustness to noise.</li>
      <li>Demonstrated reduced risk of single-point compromise.</li>
      <li>Explained workflows using simple step-by-step logic.</li>
    </ul>
  </div>

  <div class="project-block">
    <h3>The Power of Data: ML in Cyber Attack Classification</h3>
    <p><strong>Tech:</strong> Python, ML, Flask | <strong>Duration:</strong> Jan – May 2024</p>
    <ul>
      <li>Classified cyberattacks to support faster detection and response.</li>
      <li>Handled noisy and imbalanced security datasets.</li>
      <li>Chose models prioritizing precision and recall over raw accuracy.</li>
      <li>Focused KPIs on false positives and missed attack reduction.</li>
      <li>Helped stakeholders understand detection reliability by attack type.</li>
      <li>Explained results in operational terms relevant to security teams.</li>
    </ul>
  </div>

</div>

</div>
  </section>

  <footer class="site-footer">
    <div class="container">
      <small>© <span id="y"></span> Snehitha Tadapaneni</small>
    </div>
  </footer>

  <script>
    document.getElementById('y').textContent = new Date().getFullYear();
  </script>
</body>
</html>
